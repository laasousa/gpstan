---
title: "Playing with Gaussian processes"
output: 
  ghdown::github_html_document: 
    keep_md: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  comment = "#>",
  collapse = TRUE)
options(width = 85)
```

```{r}
library(rstan)
```


We have 10 observed x-y values. Use a Gaussian process to estimate y-values in
between and beyond those points.


## Estimate a Gaussian process

Here's the model in Stan.

```{r gp-fit-stan, cache = TRUE, results = 'hide'}
# Compile the model
m_exe <- stan_model("./gp-fit.stan")
```

```{r}
m_exe
```

Pass in some data.

```{r}
# Stan data
m_data <- list(
  N1 = 10, 
  x1 = 1:10, 
  y1 = as.vector(scale(lme4::sleepstudy$Reaction[1:10])))

# x values over which to predict new ys
new_xs <- seq(1, 12, by = .2)

# Remove the xs that have a known y
m_data$x2 <- new_xs[!(new_xs %in% m_data$x1)]
m_data$N2 <- length(m_data$x2)
```

Get 1,000 samples from the posterior.

```{r}
m_fit <- sampling(m_exe, m_data, chains = 1)
m_fit
```

Plot some samples from the process.

```{r gp-samples}
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)

# Create a dataframe of x values and the names of inferred y values
inferred_data_names <- tibble(
  x = m_data$x2, 
  point = sprintf("y2[%s]", seq_along(x)))

# Get the posterior samples into a long format and add the y values
posterior_inferred <- as.data.frame(m_fit) %>% 
  tibble::as_tibble() %>% 
  select(starts_with("y2"), eta_sq, rho_sq, sigma_sq) %>% 
  tibble::rowid_to_column("draw") %>% 
  tidyr::gather(point, value, -draw, -eta_sq, -rho_sq, -sigma_sq) %>% 
  left_join(inferred_data_names) %>% 
  select(draw, eta_sq, rho_sq, sigma_sq, x, y = value)

df_observed <- tibble(x = m_data$x1, y = m_data$y1)

# dataframe of process parameters
gp_parameters <- posterior_inferred %>% 
  distinct(draw, eta_sq, rho_sq, sigma_sq)

# Create a "posterior" for the observed values
posterior_observed <- df_observed %>% 
  tidyr::expand(tidyr::nesting(x, y), draw = 1:1000) %>% 
  left_join(gp_parameters, by = "draw")

posterior <- bind_rows(posterior_inferred, posterior_observed)
to_plot <- sample(unique(posterior$draw), 50)
posterior_plot <- posterior %>% 
  filter(draw %in% to_plot)

ggplot(df_observed) + 
  aes(x = x, y = y) + 
  geom_line(aes(group = draw), data = posterior_plot, alpha = .2) + 
  geom_point(size = 3) 
```

The plot seems too wiggly. I am not sure if the Stan code is 100% correct. Or
whether the problem is the sigma term.

### Parameter exploration

Plot the process at different eta and rho quartiles.

```{r gp-samples-by-parameters, fig.width = 8, fig.height = 8}
grid_definition <- posterior %>% 
  distinct(draw, eta_sq, rho_sq) %>% 
  mutate(eta_bin = ntile(eta_sq, 3),
         rho_bin = ntile(rho_sq, 3)) %>% 
  group_by(eta_bin, rho_bin) %>% 
  sample_n(20) %>% 
  ungroup()

grid_data <- posterior %>% 
  inner_join(grid_definition)

ggplot(data = grid_data) + 
  aes(x = x, y = y) + 
  geom_line(aes(group = draw), alpha = .2) + 
  geom_point(size = 3, data = df_observed) + 
  facet_grid(eta_bin ~ rho_bin, labeller = label_both)
```

## Try a noiseless model?

This is essentially the same model, but `sigma_sq` (the noise term added to the
diagonal of the matrix) is no longer an estimated parameter.

```{r gp-fit-no-noise-stan, cache = TRUE, results = 'hide'}
# Compile the model
m2_exe <- stan_model("./gp-fit-no-noise.stan")
```

```{r}
m2_exe
```

```{r}
m2_data <- m_data
m2_data$sigma_sq <- 0.001
```

```{r}
m2_fit <- sampling(m2_exe, m2_data, chains = 1)
m2_fit
```

Now, plot some samples.

```{r gp-no-noise-samples}
# Create a dataframe of x values and the names of inferred y values
inferred_data_names <- tibble(
  x = m_data$x2, 
  point = sprintf("y2[%s]", seq_along(x)))

# Get the posterior samples into a long format and add the y values
posterior_inferred <- as.data.frame(m2_fit) %>% 
  tibble::as_tibble() %>% 
  select(starts_with("y2"), eta_sq, rho_sq) %>% 
  tibble::rowid_to_column("draw") %>% 
  tidyr::gather(point, value, -draw, -eta_sq, -rho_sq) %>% 
  left_join(inferred_data_names) %>% 
  select(draw, eta_sq, rho_sq, x, y = value)

df_observed <- tibble(x = m_data$x1, y = m_data$y1)

# dataframe of process parameters
gp_parameters <- posterior_inferred %>% 
  distinct(draw, eta_sq, rho_sq)

# Create a "posterior" for the observed values
posterior_observed <- df_observed %>% 
  tidyr::expand(tidyr::nesting(x, y), draw = 1:1000) %>% 
  left_join(gp_parameters, by = "draw")

posterior <- bind_rows(posterior_inferred, posterior_observed)
to_plot <- sample(unique(posterior$draw), 50)
posterior_plot <- posterior %>% 
  filter(draw %in% to_plot)

ggplot(df_observed) + 
  aes(x = x, y = y) + 
  geom_line(aes(group = draw), data = posterior_plot, alpha = .2) + 
  geom_point(size = 3) 
```

Okay, when I don't have a sigma term, the inferred data no longer looks like
utter noise.

```{r gp-no-noise-samples-by-parameters, fig.width = 8, fig.height = 8}
grid_definition <- posterior %>% 
  distinct(draw, eta_sq, rho_sq) %>% 
  mutate(eta_bin = ntile(eta_sq, 3),
         rho_bin = ntile(rho_sq, 3)) %>% 
  group_by(eta_bin, rho_bin) %>% 
  sample_n(20) %>% 
  ungroup()

grid_data <- posterior %>% 
  inner_join(grid_definition)

ggplot(data = grid_data) + 
  aes(x = x, y = y) + 
  geom_line(aes(group = draw), alpha = .2) + 
  geom_point(size = 3, data = df_observed) + 
  facet_grid(eta_bin ~ rho_bin, labeller = label_both)
```
